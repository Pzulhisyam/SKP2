<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">Kogito 1.13.0 released!</title><link rel="alternate" href="https://blog.kie.org/2021/11/kogito-1-13-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2021/11/kogito-1-13-0-released.html</id><updated>2021-11-11T01:20:14Z</updated><content type="html">We are glad to announce that the Kogito 1.13.0 release is now available! This goes hand in hand with, , Operator, and CLI 1.13.0 release. From a feature point of view, we included a series of new features and bug fixes, including: * Data Index service new Gateway API methods for handling human task comments and attachments. * Data Index support for storing information about human task comments and attachments * Fixed memory leak in Kogito process runtime * MongoDB performance improvements with index creation for process instance ID. BREAKING CHANGES * quarkus-resteasy and quarkus-resteasy-jackson are now optional dependencies of the extension. If you omit these dependencies, you will then have to opt-out of the REST endpoint generation with kogito.generate.rest=false * existing projects will have to explicitly put quarkus-resteasy and quarkus-resteasy-jackson in their dependencies, or the Kogito extensions will raise an error.  * Kogito Operator is now installed on Cluster Scope when using OLM. For more information please take a look on . For more details head to the complete. All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found. * Kogito images are available on. * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.14.0 artifacts are available at the. A detailed changelog for 1.13.0 can be found in. New to Kogito? Check out our website. Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry><entry><title>RHEL 8.5: OpenJDK 17, .NET 6, and more</title><link rel="alternate" href="https://developers.redhat.com/articles/2021/11/10/rhel-85-openjdk-17-net-6-and-more" /><author><name>Don Pinto</name></author><id>afbb2484-89f7-46e8-9cf0-3d832265f626</id><updated>2021-11-10T09:05:00Z</updated><published>2021-11-10T09:05:00Z</published><summary type="html">&lt;p&gt;At Red Hat Summit 2019, we announced that minor releases of &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) would be available every six months. Following the success of RHEL 8.4 in May 2021, we have completed yet another exciting release of Red Hat Enterprise Linux, and &lt;a href="https://developers.redhat.com/products/rhel/download"&gt;Red Hat Enterprise Linux 8.5&lt;/a&gt; is now available. We recommend upgrading both your development and production systems to the new 8.5 release.&lt;/p&gt; &lt;p&gt;Read on for an overview of the major highlights for developers in RHEL 8.5.&lt;/p&gt; &lt;h2&gt;What's new in RHEL 8.5?&lt;/h2&gt; &lt;p&gt;With RHEL 8.5, we continue to deliver a streamlined path from development to deployment that unifies teams across a single open platform, including the tools and analytics needed to build and manage these systems on any footprint—from the data center to the cloud to the edge, and beyond. With access to the latest tools, programming languages, and enhanced &lt;a href="https://developers.redhat.com/topics/containers/"&gt;container&lt;/a&gt; capabilities, development teams can achieve faster time to value when producing new code. Learn more about the benefits that RHEL 8.5 provides in this &lt;a href="https://www.redhat.com/en/blog/whats-new-rhel-85"&gt;announcement&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Support for OpenJDK 17 and .NET 6&lt;/h3&gt; &lt;p&gt;RHEL 8.5 brings support for OpenJDK 17 and .NET 6, which lets you modernize and build next-generation workloads and applications.&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;With Red Hat’s &lt;a href="https://developers.redhat.com/products/openjdk/overview"&gt;OpenJDK 17&lt;/a&gt;, you can start using the latest long-term release of &lt;a href="https://developers.redhat.com/topics/enterprise-java/"&gt;Java&lt;/a&gt; to modernize applications and take advantage of the language's new features, while also strengthening the stability of existing application environments. One noteworthy feature of the release is an &lt;strong&gt;enhanced pseudo-random number generator,&lt;/strong&gt; which forms a common basis for many cryptographic operations, algebraic data types which simplify how complex data can be modeled, and enforcement of strict floating-point consistency for better predictability of numerically sensitive applications.&lt;/li&gt; &lt;li aria-level="1"&gt;RHEL 8.5 includes &lt;a href="https://developers.redhat.com/topics/dotnet/"&gt;.NET 6&lt;/a&gt;, which is a long-term release. In addition to x64-architecture (64-bit Intel/AMD), .NET 6 is also available for arm64 (64-bit ARM), and s390x (64-bit IBM Z). .NET Core 6 builds on the success of .NET Core 5 and adds performance improvements to the base libraries, garbage collector, and Just-In-Time (JIT) compiler. With &lt;a href="https://developers.redhat.com/topics/c/"&gt;C#&lt;/a&gt; 10 and F# 6 support, you can modernize your applications with the latest language features, such as using the new minimal API for creating web applications with less code.&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Container development tooling and base images&lt;/h3&gt; &lt;p&gt;Standardized and secure container development tooling and base images make it easier for &lt;a href="https://developers.redhat.com/topics/devops/"&gt;DevOps&lt;/a&gt; teams to build, share, and collaborate on RHEL applications.&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;The OpenJDK 17 runtime is now &lt;a href="https://catalog.redhat.com/software/containers/search?q=OpenJDK&amp;p=1&amp;vendor_name=Red%20Hat%2C%20Inc."&gt;available&lt;/a&gt; as a &lt;a href="https://www.redhat.com/en/blog/introducing-red-hat-universal-base-image"&gt;Red Hat Universal Base Image (UBI)&lt;/a&gt; container. This lets you test and upgrade applications with the new Java version as well as include the latest Java version in your CI/CD pipelines. When combined with the latest version of &lt;a href="https://developers.redhat.com/blog/2019/03/15/jdk-mission-control-red-hat-build-openjdk"&gt;JDK Mission Control&lt;/a&gt;, you can monitor and profile Java applications more easily to enhance performance.&lt;/li&gt; &lt;li aria-level="1"&gt;With native rootless user &lt;a href="https://www.redhat.com/sysadmin/podman-rootless-overlay"&gt;overlay file system support in Podman&lt;/a&gt;, enjoy an improved performance experience for building and running images, along with the added flexibility and enhanced security of rootless containers.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Looking for a specific container image? Check out the &lt;a href="https://connect.redhat.com/explore/red-hat-container-certification"&gt;Red Hat Certified Containers&lt;/a&gt; through the &lt;a href="https://catalog.redhat.com/software/containers/explore"&gt;Red Hat Ecosystem Catalog&lt;/a&gt;. This makes it easier to build and deploy applications using the supported application streams for Red Hat Enterprise Linux and &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; environments.&lt;/p&gt; &lt;h3&gt;New runtimes and web servers with application streams&lt;/h3&gt; &lt;p&gt;Red Hat Enterprise Linux 8 introduced application streams to offer greater flexibility to developers exploring different versions of software. RHEL 8.5 provides developers with the latest supported application runtimes and web server versions through application streams:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;&lt;strong&gt;Ruby 3.0&lt;/strong&gt; is a very significant version of Ruby that enables developers to build modern web applications. Ruby 3.0 offers improved performance, concurrency support, and language correctness, among other noteworthy features.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Nginx 1.20&lt;/strong&gt; brings several new features, security fixes, and enhancements over the previously released 1.18 version. These features include support for client SSL certificate validation with Online Certificate Status Protocol (OCSP), enhanced directives, and improved HTTP/2 support.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Node.js 16&lt;/strong&gt; provides several new features including improved platform support, V8 JavaScript engine version 9, and other API enhancements.&lt;/li&gt; &lt;li aria-level="1"&gt;Additionally, several &lt;a href="https://developers.redhat.com/products/gcc-clang-llvm-go-rust/overview"&gt;compiler&lt;/a&gt; packages and development tools are updated: &lt;strong&gt;Go toolset (1.16.7)&lt;/strong&gt;, &lt;strong&gt;Rust toolset (1.54.0)&lt;/strong&gt;, &lt;strong&gt;LLVM toolset (12.0.1)&lt;/strong&gt;, &lt;strong&gt;CMake (3.20.2)&lt;/strong&gt;, and &lt;strong&gt;GCC toolset (11)&lt;/strong&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;How to get started with RHEL 8.5&lt;/h2&gt; &lt;p&gt;Red Hat Enterprise Linux 8.5 continues Red Hat’s commitment to customer choice in terms of the underlying compute architecture, with availability across x86_64, ppc64le, s390x, and aarch64 hardware.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Developers with active subscriptions can access &lt;a href="https://access.redhat.com/downloads/content/479/ver=/rhel---8/8.4/x86_64/product-software"&gt;Red Hat Enterprise Linux downloads&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;If you're new to using Red Hat products, register for the &lt;a href="https://developers.redhat.com/about"&gt;Red Hat Developer program&lt;/a&gt; to get access to the Individual Developer subscription for RHEL, which can be used in production for up to 16 systems.&lt;/li&gt; &lt;li&gt;For information about a &lt;a href="https://www.redhat.com/en/blog/new-year-new-red-hat-enterprise-linux-programs-easier-ways-access-rhel#Bookmark%202"&gt;Red Hat Developer for Teams subscription&lt;/a&gt;, contact your Red Hat account representative.&lt;/li&gt; &lt;li&gt;For more details, please read the full &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/"&gt;release notes.&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/11/10/rhel-85-openjdk-17-net-6-and-more" title="RHEL 8.5: OpenJDK 17, .NET 6, and more"&gt;RHEL 8.5: OpenJDK 17, .NET 6, and more&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Don Pinto</dc:creator><dc:date>2021-11-10T09:05:00Z</dc:date></entry><entry><title>Kafka Monthly Digest: October 2021</title><link rel="alternate" href="https://developers.redhat.com/articles/2021/11/10/kafka-monthly-digest-october-2021" /><author><name>Mickael Maison</name></author><id>2bdcbe8c-6607-4b55-b6f4-4385935e2bcc</id><updated>2021-11-10T07:00:00Z</updated><published>2021-11-10T07:00:00Z</published><summary type="html">&lt;p&gt;This 45th edition of the Kafka Monthly Digest covers what happened in the &lt;a href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt; developer community in October 2021, including new milestones for Apache Kafka 3.1.0, notable Kafka Improvement Proposals (KIPs), community project releases for Debezium 1.7 and Strimzi 0.26.0, and more.&lt;/p&gt; &lt;p&gt;For last month’s digest, see &lt;a href="https://developers.redhat.com/articles/2021/10/06/kafka-monthly-digest-september-2021"&gt;Kafka Monthly Digest: September 2021&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Releases&lt;/h2&gt; &lt;p&gt;Three new Kafka versions (3.1.0, 2.7.2, and 2.6.3) are currently in progress.&lt;/p&gt; &lt;h3&gt;Apache Kafka 3.1.0&lt;/h3&gt; &lt;p&gt;The release process for Apache Kafka 3.1.0 continued in October 2021. The KIP freeze happened on October 15, and feature freeze happened on October 29. The next milestone will be the code freeze on November 12. The &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/Release+Plan+3.1.0"&gt;release plan&lt;/a&gt; is available on the Apache Kafka wiki.&lt;/p&gt; &lt;h3&gt;Kafka 2.7.2 and 2.6.3&lt;/h3&gt; &lt;p&gt;On October 8, I volunteered to run these two bugfix releases. The respective release plans for versions &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/Release+Plan+2.7.2"&gt;2.7.2&lt;/a&gt; and &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/Release+Plan+2.6.3"&gt;2.6.3&lt;/a&gt; are on the Apache Kafka wiki. Votes are currently ongoing on the first release candidates for both of these releases.&lt;/p&gt; &lt;h2&gt;Kafka Improvement Proposals&lt;/h2&gt; &lt;p&gt;Last month, the community submitted 10 &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Improvement+Proposals"&gt;KIPs&lt;/a&gt; (KIP-779 to KIP-788; note that two KIPs are currently numbered 786). I'll highlight the ones that caught my eye:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-779%3A+Allow+Source+Tasks+to+Handle+Producer+Exceptions"&gt;&lt;strong&gt;KIP-779: Allow source tasks to handle producer exceptions&lt;/strong&gt;&lt;/a&gt;: Source connectors import data from other systems into Kafka. Currently, if a record can't be imported into Kafka—if it's too large, for example—the task that generated the record will fail. This KIP proposes a mechanism that will allow that task to decide whether to fail or ignore the error.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-780%3A+Support+fine-grained+compression+options"&gt;&lt;strong&gt;KIP-780: Support fine-grained compression options&lt;/strong&gt;&lt;/a&gt;: Most modern compression algorithms expose configurations to tune them for diverse kinds of data. While Kafka supports four algorithms (gzip, LZ4, Snappy, and zstd), it does not allow you to tune them. This KIP proposes adding per-algorithm configurations to allow fine-tuning compression. Note that &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-390%3A+Support+Compression+Level"&gt;KIP-390&lt;/a&gt;, which introduced compression-level support, has not been merged yet.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-782%3A+Expandable+batch+size+in+producer"&gt;&lt;strong&gt;KIP-782: Expandable batch size in producer&lt;/strong&gt;&lt;/a&gt;: &lt;a href="https://kafka.apache.org/documentation/#producerconfigs_batch.size"&gt;&lt;code&gt;batch.size&lt;/code&gt;&lt;/a&gt; is a key producer setting; however, it's sometimes tricky to properly tune. This KIP proposes an algorithm to dynamically resize the producer batch size based on the load.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=191335433"&gt;&lt;strong&gt;KIP-786: Use localhost:9092 as default bootstrap-server/broker-list in client tools&lt;/strong&gt;&lt;/a&gt;: Currently, when using the Kafka command-line tools, you always have to provide the bootstrap servers you want to use. This KIP proposes defaulting &lt;code&gt;--bootstrap-server&lt;/code&gt; to &lt;code&gt;localhost:9092&lt;/code&gt; when a value is not explicitly provided, which will make the tools easier to use in development environments.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Community releases&lt;/h2&gt; &lt;p&gt;This section covers a few notable &lt;a href="https://developers.redhat.com/topics/open-source"&gt;open source&lt;/a&gt; community project releases:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://github.com/strimzi/strimzi-kafka-operator/releases/tag/0.26.0"&gt;&lt;strong&gt;strimzi-kafka-operator 0.26.0&lt;/strong&gt;&lt;/a&gt;: Strimzi is a Kubernetes Operator for running Kafka. Version 0.26 supports Kafka 3.0.0 and 2.8.1. It includes many Cruise Control improvements, such as an update to 2.5.73, along with support for authorization, authentication, and SSL. It also provides the option to build Kafka Connect images with plug-ins by specifying Maven URLs.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://debezium.io/blog/2021/10/04/debezium-1-7-final-released/"&gt;&lt;strong&gt;Debezium 1.7.0&lt;/strong&gt;&lt;/a&gt;: &lt;a href="https://developers.redhat.com/blog/2020/05/08/change-data-capture-with-debezium-a-simple-how-to-part-1"&gt;Debezium&lt;/a&gt; is a change data capture platform. Debezium 1.7 introduces a new web UI to manage connectors, adds support for NATS in Debezium Server, and includes significant improvements to the incremental snapshotting capabilities that were introduced in the previous release.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://github.com/Shopify/sarama/releases/tag/v1.30.0"&gt;&lt;strong&gt;Sarama 1.30.0&lt;/strong&gt;&lt;/a&gt;: Sarama is a pure Golang Kafka client. This new release adds support for Kafka 3.0, as well, for deleting offsets and managing quotas. It also adds metrics for consumer groups operations and for throttling.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Blogs&lt;/h2&gt; &lt;p&gt;Check out these interesting blog articles that were published last month:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://sixfold.medium.com/bringing-kafka-based-architecture-to-the-next-level-using-simple-postgresql-tables-415f1ff6076d"&gt;Bringing Kafka based architecture to the next level using simple PostgreSQL tables&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://medium.com/@lbroudoux/deploying-strimzi-kafka-and-java-clients-with-security-part-1-authentication-1b4e10e6ab16"&gt;Deploying Strimzi Kafka and Java clients with security, Part 1: Authentication&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://blog.rockthejvm.com/kafka-streams/"&gt;Kafka Streams 101&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;To learn more about Kafka, visit Red Hat Developer's &lt;a href="https://developers.redhat.com/topics/kafka-kubernetes"&gt;Apache Kafka topic page&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/11/10/kafka-monthly-digest-october-2021" title="Kafka Monthly Digest: October 2021"&gt;Kafka Monthly Digest: October 2021&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Mickael Maison</dc:creator><dc:date>2021-11-10T07:00:00Z</dc:date></entry><entry><title>Automating JDK Flight Recorder in containers</title><link rel="alternate" href="https://developers.redhat.com/articles/2021/11/09/automating-jdk-flight-recorder-containers" /><author><name>Andrew Azores</name></author><id>b199e10e-5fae-45a4-9e2c-9b04b41454d9</id><updated>2021-11-09T07:00:00Z</updated><published>2021-11-09T07:00:00Z</published><summary type="html">&lt;p&gt;This article is part of a series of hands-on guides to using &lt;a href="https://developers.redhat.com/articles/2021/10/18/announcing-cryostat-20-jdk-flight-recorder-containers"&gt;Cryostat 2.0&lt;/a&gt;, or JDK Flight Recorder for containers. This article introduces Cryostat's new API for automated rules. We'll walk through two use cases highlighting the API's compact but powerful rule definitions. You'll see how to use rule definitions to specify a match expression for one or more target &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; applications, and how to configure the type of flight recording you want to start on these targets.&lt;/p&gt; &lt;p&gt;Once you've created a rule, Cryostat immediately matches it against all existing discovered targets and starts your flight recording. Cryostat will also apply the rule to newly discovered targets that match its definition. You can create multiple rules to match different subsets of targets or to layer different recording options for your needs.&lt;/p&gt; &lt;p&gt;The automated rules API is brand new in Cryostat 2.0, and we haven't yet developed the user interface (UI) for it. For now, we'll use &lt;code&gt;curl&lt;/code&gt; to interact with the Cryostat HTTP API directly.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: &lt;a href="https://access.redhat.com/documentation/en-us/openjdk/11/html/release_notes_for_cryostat_2.0"&gt;The Red Hat build of Cryostat 2.0&lt;/a&gt; is now widely available in technology preview. Cryostat 2.0 introduces many new features and improvements, such as automated rules, a better API response JSON format, custom targets, concurrent target JMX connections, WebSocket push notifications, and more. The Red Hat build includes the &lt;a href="https://catalog.redhat.com/software/operators/detail/60ee049a744684587e218ef5"&gt;Cryostat Operator&lt;/a&gt; to simplify and automate Cryostat deployment on OpenShift.&lt;/p&gt; &lt;h2&gt;Use case 1: Continuous monitoring in a containerized JVM&lt;/h2&gt; &lt;p&gt;Previously, if we wanted to enable always-on continuous monitoring using JDK Flight Recorder (JFR) in a containerized Java virtual machine (JVM), we would set JVM flags on the target application, then restart the application to start monitoring. With Cryostat's automated rules, we can enable JDK Flight Recorder at runtime to continuously monitor an already-running target application, with no restart, no redeploy, and no downtime.&lt;/p&gt; &lt;p&gt;We can also adjust the continuous monitoring event template at runtime, with no downtime. First, we create a rule with the template we want to use. Then, we create a new template and a new rule with the new or updated event template. Finally, we delete the original rule with the &lt;code&gt;clean=true&lt;/code&gt; parameter. Here's the source:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt; $ export CRYOSTAT=https://cryostat.example.com # replace this URL with your actual Cryostat instance URL $ curl -F name="firstRule" -F matchExpression=”target.alias==‘com.example.MainClass’” -F eventSpecifier=”template=Profiling,type=TARGET” $CRYOSTAT/api/v2/rules # Create a Rule named firstRule using the Profiling template $ curl $CRYOSTAT/api/v1/targets/$serviceUri/templates/Profiling/type/TARGET -o profiling.jfc # Download the Profiling template to your computer $ $EDITOR profiling.jfc # Edit the Profiling template to update the event definitions inside, and to rename it from Profiling to Demo $ mv profiling.jfc demo.jfc # Rename the file to demo.jfc so it's more identifiable as the Demo profile $ curl -F template=@demo.jfc $CRYOSTAT/api/v1/templates # Upload the new Demo profile to Cryostat $ curl -F name="secondRule" -F matchExpression=”target.alias==‘com.example.MainClass’” -F eventSpecifier=”template=Demo,type=CUSTOM” $CRYOSTAT/api/v2/rules # Create a second Rule using the Demo profile $ curl -X DELETE $CRYOSTAT/api/v2/rules/firstRule?clean=true # Delete the first Rule that used the Profiling template and clean up any active recordings it created &lt;/code&gt; &lt;/pre&gt; &lt;h2&gt;Use case 2: Custom monitoring with Kubernetes labels or annotations&lt;/h2&gt; &lt;p&gt;We can define a rule that applies to any target application that has platform-specific attributes, such as &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; labels or annotations. Here's an example in JSON notation:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt; { "name": "k8sMonitoring", "description": "Enable the Demo template on any target with the jfrMonitoring=true annotation", "matchExpression": "target.annotations.platform[‘jfrMonitoring’]==’enabled’", "eventSpecifier": "template=Demo,type=CUSTOM", "archivalPeriodSeconds": 300, "preservedArchives": 12 } &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;Once we've created this rule definition, Cryostat will check all of the existing target applications and watch for new targets that appear with the &lt;code&gt;jfrMonitoring=enabled&lt;/code&gt; annotation. Any matching targets found will have a recording started automatically using the custom &lt;code&gt;Demo&lt;/code&gt; template from our first use case. It will take an archived snapshot every five minutes and maintain an hour’s worth of these archives in storage.&lt;/p&gt; &lt;p&gt;With this rule definition in place, Kubernetes or &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; users can use familiar tools like &lt;code&gt;kubectl/oc&lt;/code&gt; or the OpenShift console to mark target applications for monitoring, without needing to interact directly with the Cryostat API or UI. This opens the door to further automating your workflow.&lt;/p&gt; &lt;p&gt;As an example, you might use or implement an Operator that monitors traffic flow or pod restarts and enables monitoring on pods after some criterion threshold is met, then disables it again if the target application's behavior returns to normal. As a Kubernetes administrator, you could receive a notification when this occurs and check the Cryostat archives to retrieve JDK Flight Recorder data from the target application recorded during the problematic period, or you could view these archived recordings in Cryostat’s Grafana dashboard.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: An important caveat is that Cryostat does not watch for changes in the Kubernetes annotations or labels; it only watches to see if target applications appear or disappear. To apply the annotation to a target application, we must apply the annotation or label to the application &lt;em&gt;pod&lt;/em&gt; (which will cause Kubernetes to roll out a new replica), and not to the &lt;em&gt;deployment&lt;/em&gt;.&lt;/p&gt; &lt;h2&gt;How to use match expressions in Cryostat&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;matchExpression&lt;/code&gt; in a rule definition is a Java-like snippet of code that Cryostat interprets and uses to determine if a rule should be applied to any given target.  &lt;code&gt;matchExpressions&lt;/code&gt; should thus evaluate to a &lt;code&gt;boolean&lt;/code&gt; value. The simplest &lt;code&gt;matchExpression&lt;/code&gt;s would be the booleans &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt;; if we use &lt;code&gt;true&lt;/code&gt;, the rule will apply to every target. The expression has a target object in global scope, with the following form in JSON notation:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt; { “alias”: “myAppAlias”, “connectUrl”: “service:jmx:rmi:///jndi/rmi://cryostat:9091/jmxrmi”, “labels”: { “com.example/service”: “customer-login”, }, “annotations”: { “platform”: { “io.kubernetes/annotation”: “annotated” }, “cryostat”: { “PORT”: 9091, “HOST”: “cryostat”, “NAMESPACE”: “myproject” } } } &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;The &lt;code&gt;alias&lt;/code&gt;, &lt;code&gt;connectUrl&lt;/code&gt;, &lt;code&gt;labels&lt;/code&gt;, &lt;code&gt;annotations.platform&lt;/code&gt;, and &lt;code&gt;annotations.cryostat&lt;/code&gt; properties are all guaranteed to be present on the target object. &lt;code&gt;alias&lt;/code&gt; and &lt;code&gt;connectUrl&lt;/code&gt; will be non-empty strings. The &lt;code&gt;labels&lt;/code&gt; and &lt;code&gt;platform&lt;/code&gt; annotations may be empty—in OpenShift or Kubernetes, these are populated from the labels and annotations applied to the target’s pod, if any. The Cryostat annotations map will vary per platform, but on OpenShift or Kubernetes you can expect the &lt;code&gt;HOST&lt;/code&gt;, &lt;code&gt;PORT&lt;/code&gt;, &lt;code&gt;NAMESPACE&lt;/code&gt;, and &lt;code&gt;POD_NAME&lt;/code&gt; keys to be present and non-empty.&lt;/p&gt; &lt;p&gt;Here are some examples of &lt;code&gt;matchExpression&lt;/code&gt;s:&lt;/p&gt; &lt;pre&gt; target.alias == ’com.example.MainClass’ target.alias == ’myAlias’ target.labels[‘com.example/service’] == ’customer-login’ target.labels[‘com.example/service’] != ’customer-login’ target.annotations.cryostat.PORT &gt; 3000 target.annotations.cryostat.PORT &gt; 3000 &amp;&amp; target.annotations.platform[‘io.kubernetes/annotation’] == ‘enabled’ !!target.annotations.platform[‘io.kubernetes/annotation’] /^customer-login[0-9]*$/.test(target.alias) &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, you've learned how to use match expressions to create automated rules for Cryostat monitoring. Once you've set up your automated rules, Cryostat will continuously monitor applications that meet the criteria defined in those rules, with no need to restart or redeploy those applications. Visit &lt;a href="http://cryostat.io/"&gt;Cryostat.io&lt;/a&gt; and see the following articles for further details:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2021/01/25/introduction-to-containerjfr-jdk-flight-recorder-for-containers"&gt;Introduction to Cryostat: JDK Flight Recorder for containers&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/10/18/announcing-cryostat-20-jdk-flight-recorder-containers"&gt;Get started with Cryostat 2.0&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/10/26/configuring-java-applications-use-cryostat"&gt;Configuring Java applications to use Cryostat&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/11/02/java-monitoring-custom-targets-cryostat"&gt;Java monitoring for custom targets with Cryostat&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/11/09/automating-jdk-flight-recorder-containers" title="Automating JDK Flight Recorder in containers"&gt;Automating JDK Flight Recorder in containers&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Andrew Azores</dc:creator><dc:date>2021-11-09T07:00:00Z</dc:date></entry><entry><title>Optimize Node.js images with the UBI 8 Node.js minimal image</title><link rel="alternate" href="https://developers.redhat.com/articles/2021/11/08/optimize-nodejs-images-ubi-8-nodejs-minimal-image" /><author><name>Bethany Griggs</name></author><id>149b1d15-d2e0-47fb-8691-4784de20394a</id><updated>2021-11-08T07:00:00Z</updated><published>2021-11-08T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js 14&lt;/a&gt; is available as a &lt;a href="https://catalog.redhat.com/software/containers/ubi8/nodejs-14-minimal/6065b8e1b92fbda3a4c65d91?container-tabs=overview"&gt;UBI (Universal Base Image) minimal image&lt;/a&gt; on &lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt;. Minimal images are typically used in conjunction with a &lt;a href="https://catalog.redhat.com/software/containers/ubi8/nodejs-14/5ed7887dd70cc50e69c2fabb?container-tabs=overvie"&gt;larger build image&lt;/a&gt;. The larger builder image contains all the dependencies and tools needed for your application’s build process, whereas the smaller runtime image contains just the dependencies needed to run your application.&lt;/p&gt; &lt;p&gt;The UBI minimal images minimize what is included in the image to reduce their size. For example, the full Node.js 14 UBI image is about 225MB (610MB uncompressed), whereas the slim image is about 70MB (189MB uncompressed), less than a third the size. A smaller image means less code in production, which in turn reduces your deployment’s potential attack surface and potentially speeds up your builds. You can read more about UBI minimal images in its &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/building_running_and_managing_containers/index#con_understanding-the-ubi-minimal-images_assembly_types-of-container-images"&gt;documentation&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;You can deploy the Node.js minimal image through various deployment methods. This article shows you how to use the images through Dockerfiles and through chained builds on &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;A minimal image with a Dockerfile&lt;/h2&gt; &lt;p&gt;To use the Node.js image in a Dockerfile, follow these steps:&lt;/p&gt; &lt;ol&gt;&lt;li&gt; &lt;p&gt;Pull the base images for the builder and minimal runtime images:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ docker pull registry.access.redhat.com/ubi8/nodejs-14:latest $ docker pull registry.access.redhat.com/ubi8/nodejs-14-minimal:latest&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Clone your Node.js application. You can use the following &lt;a href="https://github.com/nodeshift-starters/nodejs-rest-http"&gt;example application&lt;/a&gt;, or adapt the rest of these steps to your own Node.js application: &lt;pre&gt; &lt;code&gt;$ git clone https://github.com/nodeshift-starters/nodejs-rest-http.git&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Create the multistage Dockerfile with the following content:&lt;br /&gt;   &lt;pre&gt; &lt;code&gt;# Install the application dependencies in a full UBI Node docker image FROM registry.access.redhat.com/ubi8/nodejs-14:latest # Copy package.json and package-lock.json COPY package*.json ./ # Install app dependencies RUN npm install --production # Copy the dependencies into a minimal Node.js image FROM registry.access.redhat.com/ubi8/nodejs-14-minimal:latest # Install app dependencies COPY --from=0 /opt/app-root/src/node_modules /opt/app-root/src/node_modules COPY . /opt/app-root/src ENV NODE_ENV production ENV PORT 3000 EXPOSE 3000 CMD ["npm", "start"]&lt;/code&gt;&lt;/pre&gt; The Dockerfile uses the &lt;code&gt;ubi8/nodejs-14&lt;/code&gt; image to handle the build process, which in this case is &lt;code&gt;npm install --production&lt;/code&gt;. The &lt;code&gt;node_module&lt;/code&gt; assets are then copied into the second image, which is based on the minimized &lt;code&gt;ubi8/nodejs-14-minimal&lt;/code&gt; image.&lt;br /&gt;&lt;br /&gt; A copy of this Dockerfile is available &lt;a href="https://github.com/nodeshift/docker/blob/main/Dockerfile-run"&gt;on GitHub&lt;/a&gt;. The Dockerfile assumes the use of &lt;a href="https://expressjs.com/"&gt;Express.js&lt;/a&gt; and hosts the application on port 3000, but can be adjusted as necessary for your application.&lt;/li&gt; &lt;li&gt;Build the image and run your containerized application: &lt;pre&gt; &lt;code class="language-bash"&gt;$ docker build --tag nodejs-app . $ docker run --publish 3000:3000 nodejs-app &gt; nodejs-rest-http@4.0.0 start /opt/app-root/src &gt; node . [1627920401838] INFO (17 on 3dc9969e3f2b): Listening on port 3000&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If you’re using our sample application, it should be accessible at &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;To stop the container from running, press Ctrl+C in your terminal.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt;&lt;p&gt;These steps have demonstrated the Docker multistage build flow, where we build the application in the larger builder image and then copy the assets into a smaller runtime image.&lt;/p&gt; &lt;h2&gt;A minimal image in OpenShift with Source-to-Image chained builds&lt;/h2&gt; &lt;p&gt;Within OpenShift, the minimal image can be used with a &lt;a href="https://docs.openshift.com/container-platform/4.7/cicd/builds/advanced-build-operations.html#builds-chaining-builds_advanced-build-operations"&gt;chained build&lt;/a&gt; process. In this case, you’ll use the &lt;code&gt;nodejs:14-ubi8&lt;/code&gt; image stream to handle your application's build, and then use the &lt;code&gt;nodejs:14-ubi8-minimal&lt;/code&gt; image stream as the runtime image.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;nodejs:14-ubi8-minimal&lt;/code&gt; image stream is available by default in OpenShift versions 4.9+. In previous versions, you can import the &lt;code&gt;nodejs:14-ubi8-minimal&lt;/code&gt; image stream using the following command with the OpenShift command-line tool:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc apply -f https://raw.githubusercontent.com/sclorg/s2i-nodejs-container/master/imagestreams/nodejs-rhel.json -n openshift&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In this example, we’ll demonstrate how to implement a chained build flow using two &lt;a href="https://docs.openshift.com/container-platform/4.1/builds/understanding-buildconfigs.html#builds-buildconfig_understanding-builds"&gt;BuildConfigs&lt;/a&gt;.&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Log into your OpenShift cluster and select the &lt;code&gt;default&lt;/code&gt; namespace.&lt;/li&gt; &lt;li&gt;From the &lt;strong&gt;Administrator&lt;/strong&gt; view, select &lt;strong&gt;Builds → &lt;/strong&gt;&lt;strong&gt;Image Streams&lt;/strong&gt; to create two new image streams, naming them &lt;code&gt;nodejs-builder-image&lt;/code&gt; and &lt;code&gt;nodejs-runtime-image&lt;/code&gt;. You need to change the &lt;code&gt;metadata.name&lt;/code&gt; value for each image stream to &lt;code&gt;nodejs-builder-image &lt;/code&gt;and &lt;code&gt;nodejs-runtime-image&lt;/code&gt;, respectively.&lt;/li&gt; &lt;li&gt;Next, create the first BuildConfig, which defines the builder image using the &lt;a href="https://github.com/openshift/source-to-image"&gt;Source-to-Image (S2I)&lt;/a&gt; strategy. The output of the build is then pushed to the &lt;code&gt;nodejs-builder-image&lt;/code&gt; Image stream. Create a new BuildConfig by choosing &lt;strong&gt;Builds → BuildConfig&lt;/strong&gt;, with the following YAML configuration: &lt;pre&gt; &lt;code&gt;apiVersion: build.openshift.io/v1 kind: BuildConfig metadata: namespace: default name: nodejs-builder-image spec: output: to: kind: ImageStreamTag name: nodejs-builder-image:latest source: git: uri: https://github.com/nodeshift-starters/nodejs-rest-http strategy: sourceStrategy: from: kind: ImageStreamTag name: nodejs:14-ubi8 namespace: openshift&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This example configures the BuildConfig to build an example Node.js application called &lt;a href="https://github.com/nodeshift-starters/nodejs-rest-http"&gt;nodejs-rest-http&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Create the second BuildConfig. This BuildConfig takes the resulting image from the &lt;code&gt;nodejs-builder-image&lt;/code&gt; Image Stream and copy the application source and build artifacts. A new runtime image is created on top of the Node.js minimal image, with the application code copied in and ready to run. The resulting runtime image is then pushed into the &lt;code&gt;nodejs-runtime-image&lt;/code&gt; image stream. The configuration is: &lt;pre&gt; &lt;code&gt;apiVersion: build.openshift.io/v1 kind: BuildConfig metadata: namespace: default name: nodejs-runtime-image spec: output: to: kind: ImageStreamTag name: nodejs-runtime-image:latest source: dockerfile: |- FROM nodejs:14-ubi8-minimal COPY src $HOME CMD /usr/libexec/s2i/run images: - from: kind: ImageStreamTag name: nodejs-builder-image:latest paths: - sourcePath: /opt/app-root/src destinationDir: "." strategy: dockerStrategy: from: kind: ImageStreamTag namespace: openshift name: nodejs:14-ubi8-minimal triggers: - imageChange: from: kind: "ImageStreamTag" name: "nodejs-builder-image:latest" type: ImageChange&lt;/code&gt;&lt;/pre&gt; Note the &lt;code&gt;ImageChange&lt;/code&gt; trigger. This launches a runtime build upon each new build of &lt;code&gt;nodejs-builder-image:latest&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Now start a build based on the &lt;code&gt;nodejs-builder-image&lt;/code&gt; BuildConfig. You can do this by navigating to the BuildConfig view, expanding the actions menu (three vertical dots), and clicking &lt;strong&gt;Start Build&lt;/strong&gt; as shown in Figure 1. &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/buildconfigs.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/buildconfigs.png?itok=XnvczZr_" width="1440" height="859" alt="The actions menu provides a "Start build" action on the BuildConfigs interface." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. Starting a build in the BuildConfigs interface. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;/li&gt; &lt;li&gt;Once the new build is requested, you are taken to the &lt;strong&gt;Build Details&lt;/strong&gt; view (Figure 2). You can click the &lt;strong&gt;Logs&lt;/strong&gt; tab to follow the progress of the build. &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/details.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/details.png?itok=U0pD9hOu" width="1440" height="680" alt="The "Build details" page shows details about the image." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2. Build details page displayed after you request a build. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;/li&gt; &lt;li&gt;Once the &lt;code&gt;nodejs-builder-image&lt;/code&gt; build is complete, a &lt;code&gt;nodejs-runtime-image&lt;/code&gt; build is automatically started. If you navigate to the &lt;strong&gt;Builds&lt;/strong&gt; interface, you should see a new &lt;code&gt;nodejs-runtime-image&lt;/code&gt; build (Figure 3). &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/builds_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/builds_0.png?itok=u3oyn8bl" width="1440" height="702" alt="The Builds interface shows completed builds." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3. Builds interface. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;/li&gt; &lt;li&gt;After the &lt;code&gt;nodejs-runtime-image&lt;/code&gt; build is complete, you can deploy a container based on that image. Switch to the &lt;strong&gt;Developer&lt;/strong&gt; view of OpenShift and select the &lt;strong&gt;+Add&lt;/strong&gt; interface (Figure 4). &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/add_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/add_0.png?itok=-y7aKK72" width="1440" height="703" alt="The Add interface lets you deploy a container based on an image." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4. Add interface. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;/li&gt; &lt;li&gt;We want to deploy the container from an image stream tag. Click &lt;strong&gt;Container images&lt;/strong&gt; and then select &lt;strong&gt;I&lt;/strong&gt;&lt;strong&gt;mage stream tag from internal registry&lt;/strong&gt; (Figure 5). Populate the &lt;strong&gt;Image Stream&lt;/strong&gt; with &lt;code&gt;nodejs-runtime-image&lt;/code&gt; and &lt;strong&gt;Tag&lt;/strong&gt; the image with &lt;code&gt;latest&lt;/code&gt;. You can accept all the other defaults and click &lt;strong&gt;Create&lt;/strong&gt;. &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/deploy.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/deploy.png?itok=yYzZbXpZ" width="1440" height="650" alt="On the Deploy Image interface, you can choose "t Image stream tag from internal registry"." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5. Deploy Image interface. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;/li&gt; &lt;li&gt;You are next taken to the &lt;strong&gt;Topology&lt;/strong&gt; view. The ring in the deployment turns blue when the container is deployed and running. You can then click the highlighted icon to access the running application (Figure 6). &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/topology.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/topology.png?itok=LLTdq6Pe" width="986" height="734" alt="The Topology view shows when an image is running." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6. Topology view. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;/li&gt; &lt;/ol&gt;&lt;p&gt;If you used our sample application for this exercise, you should expect to see the sample "Greeting service" application running.&lt;/p&gt; &lt;p&gt;This is an example of how you can configure a multistage build/runtime flow using OpenShift BuildConfigs. The example uses a Git build input trigger, but the same multistage flow could be replicated in more complex build configurations.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Images fully stocked with development tools are necessary for building applications but become unnecessary burdens when run in production. This article showed how to use the build and minimal images on Red Hat Enterprise Linux and OpenShift to optimize your runtime images.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/11/08/optimize-nodejs-images-ubi-8-nodejs-minimal-image" title="Optimize Node.js images with the UBI 8 Node.js minimal image"&gt;Optimize Node.js images with the UBI 8 Node.js minimal image&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Bethany Griggs</dc:creator><dc:date>2021-11-08T07:00:00Z</dc:date></entry><entry><title type="html">Red Hat Summit Connect Partner Experience Dublin - Exploring Open Source Success at Scale</title><link rel="alternate" href="http://www.schabell.org/2021/11/red-hat-summit-connect-partner-experience-dublin.html" /><author><name>Eric D. Schabell</name></author><id>http://www.schabell.org/2021/11/red-hat-summit-connect-partner-experience-dublin.html</id><updated>2021-11-08T06:00:00Z</updated><content type="html">The  is a one day event,  part of a new series of small-scale events, that brings the discussion of open source technology to your local cities.  The day provides updates and insights into the latest technologies and will also offer the opportunity to get hands on with Red Hat technologies.  There will be different streams of session topics that will host tech talks led by Red Hat experts and also business focused sessions delivered from industry leaders including some fantastic partner and customer stories. I've been invited to give a session in Dublin and wanted to share the planning with you for this event in November.  At the Red Hat Summit Connect Partner Experience in Dublin will be hosted at: Date: Wednesday 10 November 2021 Time: 2:30pm-5:45pm GMT Location: The Gibson Hotel, Point Square, North Dock, Dublin, D01 X2P2, Ireland I've been asked to share my insights into some of our larger architectures and explore how open source can be used at scale, so I'm putting together the following session for you. You've heard of large scale open source architectures, but have you ever wanted to take a serious look at these real life enterprise implementations that scale? This session takes attendees on a tour of multiple use cases covering enterprise challenges like integration, optimisation, cloud adoption, hybrid cloud management, and much more. Not only are these architectures interesting, but they are successful real life implementations featuring open source technologies and power many of your own online experiences. The attendee departs this session with a working knowledge of how to map general open source technologies to their solutions. Material covered is available freely online and attendees can use these solutions as starting points for aligning to their own solution architectures. Join us for an hour of power as we talk architecture shop!  Time: 3:45pm-4:15pm (local time)  and hope to see you there!</content><dc:creator>Eric D. Schabell</dc:creator></entry><entry><title>Improve UDP performance in RHEL 8.5</title><link rel="alternate" href="https://developers.redhat.com/articles/2021/11/05/improve-udp-performance-rhel-85" /><author><name>Paolo Abeni</name></author><id>9a9e3a72-5898-4989-b1ab-94d81ece8ae1</id><updated>2021-11-05T07:00:00Z</updated><published>2021-11-05T07:00:00Z</published><summary type="html">&lt;p&gt;If you have ever tested throughput performance in a container deployment, you know that the UDP protocol is (a lot) slower than TCP. How can that be possible? After all, the TCP protocol is extremely complex, whereas UDP is simple and carries less per-packet overhead. This article will explain the not-so-dark magic beyond the superior TCP throughput performance and how recent improvements in the &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; kernel can close that gap. You'll also learn how to use all these shiny new features in the upcoming version 8.5 of &lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt; to boost UDP throughput in container deployments by a factor of two or more.&lt;/p&gt; &lt;h2&gt;Bulk transfers and packet aggregation through TSO and GRO&lt;/h2&gt; &lt;p&gt;The typical container network infrastructure is quite complex. When a container sends a packet, it traverses the kernel network stack inside the container itself, reaches a virtual Ethernet (veth) device, and is forwarded on the peer veth device to reach the host virtual network. The host then forwards the packet towards a Linux or &lt;a href="https://www.openvswitch.org/"&gt;Open vSwitch (OVS)&lt;/a&gt; bridge and eventually over a UDP tunnel. Finally, the packet reaches the hardware network interface card (NIC). Figure 1 illustrates the sequence of packet transmissions.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/sequence.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/sequence.png?itok=JgulxvNW" width="675" height="360" alt="A network packet in a container must pass through many software components to reach the hardware device that sends it out on the network." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. A network packet in a container must pass through many software components to reach the hardware device that sends it out on the network. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;A packet coming in on the wire, targeting the container, will go through the same path in the reverse direction.&lt;/p&gt; &lt;p&gt;It's easy to guess that the CPU time needed to perform all the forwarding and encapsulation steps is easily far greater than the actual transport protocol processing time, regardless of the actual complexity of the protocol—whether UDP, TCP, or MPTCP. Additionally, the container orchestration adds significant overhead due to the complex forwarding ruleset needed to cope with multiple containers per host, etc.&lt;/p&gt; &lt;p&gt;TCP and MPTCP can alleviate the forwarding overhead thanks to aggregation. On the transmit side, the data stream is glued into packets larger than the current TCP maximum segment size (MSS). The large packets traverse the whole virtual network unmodified until they land on the real NIC. In the most common scenario, the NIC itself segments the large packet into MSS-size ones via Transmit Segmentation Offload (TSO).&lt;/p&gt; &lt;p&gt;In the reverse path, the packets received by the NIC are aggregated into large ones before entering the network stack. The received packet aggregation is usually performed by the CPU and is called Generic Receive Offload (GRO). Some NICs have hardware offload capability for GRO too.&lt;/p&gt; &lt;p&gt;In both cases (receive and transmit), a single aggregated packet amortizes the high virtual network forwarding cost for multiple packets received or sent on the wire. The key point is that such aggregation is not available by default for the UDP protocol, and each UDP packet has to pay the full forwarding overhead.&lt;/p&gt; &lt;h2&gt;Generic Receive Offload for UDP—why not?&lt;/h2&gt; &lt;p&gt;The TCP protocol is stream-oriented. Therefore, its data can be segmented in as many packets as needed, as long as the data stream can be reconstructed while preserving the data integrity. In contrast, the UDP protocol is packet-based: The data is transmitted in units (packets) whose size is specified by the user-space application. Splitting a single UDP packet into multiple ones or aggregating multiple UDP packets in a single one may confuse the recipient, which relies on the packet length to identify the application layer message size.&lt;/p&gt; &lt;p&gt;Due to all the considerations discussed so far, the Linux kernel has long supported GRO/TSO for the TCP protocol only.&lt;/p&gt; &lt;p&gt;Since Linux 4.18, thanks to QUIC—a reliable transport protocol built on top of UDP—the Linux UDP implementation has gained TSO support. It's up to the application to enable UDP segmentation on a per-socket basis and then pass the aggregated UDP packets to the kernel and the target length for the on-the-wire packet. Because this feature is a per-application opt-in, the peers by design understand that the application message size is potentially different from the transmitted or received UDP packet size.&lt;/p&gt; &lt;p&gt;TSO support can significantly improve the performance of UDP transmits in containers. But the improvement doesn't assist the receive path.&lt;/p&gt; &lt;p&gt;More recently, in Linux 5.10, the UDP protocol has additionally gained GRO support. This side of the aggregation process is also enabled on a per-socket basis. Once the application sets the relevant socket option, &lt;code&gt;UDP_GRO&lt;/code&gt;, the network stack starts aggregating incoming packets directed to the relevant socket in a process similar to what it was already doing for TCP.&lt;/p&gt; &lt;p&gt;With GRO in place, even the container receive path could potentially see the benefit of packets aggregation. Still, a few significant problems stand out. Because both TSO and GRO must be enabled explicitly from the user-space applications, only a few would go to the trouble. Additionally, a virtual network is often built on top of UDP tunnel virtual devices, and the initial UDP GRO implementation did not support them.&lt;/p&gt; &lt;h2&gt;The missing Linux kernel pieces&lt;/h2&gt; &lt;p&gt;But the Linux network community never sleeps—literally, have a look at the timestamps on the email sent by the main contributors on the mailing list—and system-wide UDP GRO support has long been only a few bits away: the kernel just needed to segment back the UDP aggregated packet as needed. For example, an aggregated UDP GRO packet could land on a socket lacking the &lt;code&gt;UDP_GRO&lt;/code&gt; option due to some complex forwarding configuration. Segmenting the aggregated packet avoids confusing the receiver application with unexpected large datagrams. System-wide UDP GRO was implemented upstream with Linux 5.12. This feature still requires some kind of opt-in: It is off by default, and the system administrator can enable it on a per-network device basis.&lt;/p&gt; &lt;p&gt;Shortly afterward, with version 5.14, Linux gained additional support for UDP over UDP-tunnel GRO, again an opt-in feature that a system admin could enable the same way as basic UDP GRO. All the pieces needed to leverage TSO/GRO end-to-end for UDP application were in place—almost: UDP applications still have to enable TSO on the transmit side explicitly.&lt;/p&gt; &lt;p&gt;What about the existing applications with no built-in TSO support? The complexity in the container virtual network setup can be of some help, for once. Packets generated inside the container have to traverse a veth pair. Virtual ethernet forwarding is usually a straightforward and fast operation, but it can also be configured to optionally trigger GRO. This is usually not needed for TCP packets because they reach the veth already aggregated. But few user-space applications aggregate UDP packets.&lt;/p&gt; &lt;p&gt;Before Linux 5.14, to enable GRO on veth devices, a system administrator was required to attach an &lt;a href="https://developers.redhat.com/blog/2018/12/06/achieving-high-performance-low-latency-networking-with-xdp-part-1"&gt;eXpress Data Path (XDP)&lt;/a&gt; program to the veth pair. Linux 5.14 removes that constraint: Instead, by exploiting the GRO stage in the veth pair, the container virtual networking software can transparently aggregate UDP packets and forward them in the aggregate form for most of the virtual network topology, greatly reducing the overhead of forwarding.&lt;/p&gt; &lt;h2&gt;Availability in Red Hat Enterprise Linux 8.5&lt;/h2&gt; &lt;p&gt;So far, we have talked about the upstream Linux kernel project, but production deployments rarely use an upstream kernel. It's reasonable to ask when you'll be able to use all the enhancements described in this article in your preferred distro of choice? Very soon: All the relevant patches and features will land in the upcoming Red Hat Enterprise Linux 8.5.&lt;/p&gt; &lt;p&gt;Sounds great—your containerized UDP application will run twice as fast. Or not, since you have to enable something and you don't know what the heck to do. The next release of &lt;a href="https://developers.redhat.com/openshift"&gt;OpenShift Container Platform (OCP)&lt;/a&gt; will enable this feature, so the system administrator won't have to bother with additional setup. But if you can't wait, let's look at the gory configuration details.&lt;/p&gt; &lt;h2&gt;Enabling UDP GRO hands-on&lt;/h2&gt; &lt;p&gt;To enable GRO for UDP in a typical container virtual network setup, the sysadmin must:&lt;/p&gt; &lt;ol&gt;&lt;li&gt; &lt;p&gt;Enable GRO on the veth peer in the main network namespace:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;VETH=&lt;veth device name&gt; CPUS=`/usr/bin/nproc` ethtool -K $VETH gro on ethtool -L $VETH rx $CPUS tx $CPUS echo 50000 &gt; /sys/class/net/$VETH/gro_flush_timeout &lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Enable GRO forwarding on that device: &lt;pre&gt; &lt;code class="language-bash"&gt;ethtool -K $VETH rx-udp-gro-forwarding on &lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Enable GRO forwarding on the NIC connected to the wire: &lt;pre&gt; &lt;code class="language-bash"&gt;DEV=&lt;real NIC name&gt; ethtool -K $DEV rx-udp-gro-forwarding on &lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt;&lt;p&gt;The first step requires some additional explanation. The veth device performs the GRO activity on a per receive queue basis. The &lt;code&gt;ethtool -L&lt;/code&gt; command configures the number of active veth receive queues to match the number of CPUs on the host. That configuration prevents contention while scheduling and running GRO.&lt;/p&gt; &lt;p&gt;To allow the GRO engine to aggregate multiple packets, the veth needs to stage the eligible packets into the GRO engine. Traditional NICs implement this strategy in hardware on top of interrupt requests, but veth devices don't provide such a capability. Instead, with the provided settings, when a packet is staged into the GRO engine, the kernel sets a software timeout. When the timeout expires, the GRO engine is flushed. The &lt;code&gt;echo&lt;/code&gt; command in step 1 configures the timeout in nanoseconds. The higher the timeout, the higher the chance that multiple packets will be aggregated—but at the expense of introducing a higher latency.&lt;/p&gt; &lt;p&gt;This example sets the timeout to 50 microseconds, which is high enough to aggregate a reasonable number of UDP packets under a significant load while keeping the added latency acceptably low for most applications. This value should likely work for all except strict, hard real-time environments.&lt;/p&gt; &lt;p&gt;After you issue the preceding commands, any containerized application using UDP transparently benefits from GRO forwarding.&lt;/p&gt; &lt;h2&gt;Benchmarking GRO&lt;/h2&gt; &lt;p&gt;We measured the gain of GRO by running the &lt;code&gt;iperf&lt;/code&gt; tool at both ends of a connection in different compute nodes. Using a pair of nodes connected with a 10Gbps Ethernet link and a packet size equal to the allowed maximum transmission unit (MTU), we got the results shown in Figure 2. GRO showed a notable improvement in speed until we reached 16 or more concurrent flows, at which point even the vanilla kernel was able to reach the link speed limit. Even when the speeds were the same, CPU utilization with GRO forwarding was almost halved.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="A bar chart depicting UDP GRO forwarding performances." data-entity-type="file" data-entity-uuid="91f44e60-11b2-4440-8f8b-124892499368" src="https://developers.redhat.com/sites/default/files/inline-images/vanilla_UDP%20GRO%20forwarding%20enabled_0.png" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 2. UDP packet flows are much faster on kernels with UDP TSO/GRO, although the advantage decreases as the number of flows increases.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Successive Linux kernels have greatly reduced the penalty of using UDP, an improvement especially noticeable in containers. We recommend that you adopt Red Hat Enterprise Linux 8.5 or another distribution with an up-to-date Linux kernel and enable UDP TSO/GRO globally on your systems.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/11/05/improve-udp-performance-rhel-85" title="Improve UDP performance in RHEL 8.5"&gt;Improve UDP performance in RHEL 8.5&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Paolo Abeni</dc:creator><dc:date>2021-11-05T07:00:00Z</dc:date></entry><entry><title type="html">Eclipse Vert.x 3.9.10 released!</title><link rel="alternate" href="https://vertx.io/blog/eclipse-vert-x-3-9-10" /><author><name>Julien Viet</name></author><id>https://vertx.io/blog/eclipse-vert-x-3-9-10</id><updated>2021-11-05T00:00:00Z</updated><content type="html">Eclipse Vert.x version 3.9.10 has just been released. It fixes quite a few bugs that have been reported by the community.</content><dc:creator>Julien Viet</dc:creator></entry><entry><title type="html">RESTEasy 5.0.0 Released</title><link rel="alternate" href="https://resteasy.github.io/2021/11/04/resteasy-5.0.0-release/" /><author><name /></author><id>https://resteasy.github.io/2021/11/04/resteasy-5.0.0-release/</id><updated>2021-11-04T18:11:11Z</updated><dc:creator /></entry><entry><title type="html">How to debug WildFly security issues</title><link rel="alternate" href="http://www.mastertheboss.com/jbossas/jboss-security/how-to-debug-wildfly-security-issues/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=how-to-debug-wildfly-security-issues" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/jbossas/jboss-security/how-to-debug-wildfly-security-issues/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=how-to-debug-wildfly-security-issues</id><updated>2021-11-04T17:22:37Z</updated><content type="html">In this article we will discuss how to troubleshoot WildFly security issues by enabling the right Loggers or System Properties. WildFly security framework is based on Elytron. Before WildFly 25, you could still use Picketbox legacy framework. This is however discuss in the second part of this article. To debug WildFly security issues the main ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry></feed>
